#!/usr/bin/env python3
"""
A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ Streamlitå¯è¦–åŒ–ã‚¢ãƒ—ãƒª

ã“ã‚Œã§å®Ÿè¡Œ
streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import os
from pathlib import Path
import subprocess
import time
import signal
import psutil

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
        page_title="ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded"
        )


# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
.metric-card {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    border-left: 4px solid #ff6b6b;
    
    /* --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆä¿®æ­£ã®æ ¸ã¨ãªã‚‹éƒ¨åˆ† --- */
    height: 100%; /* è¦ªè¦ç´ (ã‚«ãƒ©ãƒ )ã®é«˜ã•ä¸€æ¯ã«åºƒãŒã‚‹ */
    display: flex; /* Flexboxã‚’æœ‰åŠ¹åŒ– */
    flex-direction: column; /* è¦ç´ ã‚’ç¸¦ã«ä¸¦ã¹ã‚‹ */
}

.metric-card h3 {
    /* ã‚¿ã‚¤ãƒˆãƒ« (ä¾‹: "è§£æ±ºç‡") */
    margin-bottom: 0.5rem; /* ã‚¿ã‚¤ãƒˆãƒ«ã¨æ•°å€¤ã®é–“ã®ä½™ç™½ */
}

.metric-card h2 {
    /* ãƒ¡ã‚¤ãƒ³ã®æ•°å€¤ (ä¾‹: "83/83") */
    margin-bottom: 0.25rem; /* æ•°å€¤ã¨èª¬æ˜æ–‡ã®é–“ã®ä½™ç™½ */
}

.metric-card p {
    /* èª¬æ˜æ–‡ (ä¾‹: "100.0%") */
    margin-top: auto; /* â˜…â˜…â˜… ã“ã‚ŒãŒé‡è¦: è¦ç´ ã‚’ã‚³ãƒ³ãƒ†ãƒŠã®ä¸‹éƒ¨ã«æŠ¼ã—ã‚„ã‚‹ â˜…â˜…â˜… */
    color: #64748b; /* èª¬æ˜æ–‡ã®æ–‡å­—è‰²ã‚’å°‘ã—è–„ãã™ã‚‹ */
    font-size: 0.9rem; /* èª¬æ˜æ–‡ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’å°‘ã—å°ã•ãã™ã‚‹ */
    padding-top: 0.5rem; /* ä¸Šã®è¦ç´ ã¨ã®é–“ã«å°‘ã—ä½™ç™½ã‚’ç¢ºä¿ */
}

/* å„ã‚«ãƒ¼ãƒ‰ã®å·¦æ ç·šã®è‰² */
.success-metric {
    border-left-color: #51cf66;
}
.warning-metric {
    border-left-color: #ffd43b;
}
.info-metric {
    border-left-color: #339af0;
}
</style>
""", unsafe_allow_html=True)

def to_serializable(obj):
    """json.dump ã® default ã§ä½¿ã†: NumPy å‹ â†’ ãƒã‚¤ãƒ†ã‚£ãƒ–å‹"""
    if isinstance(obj, (np.integer,)):
        return int(obj)
    if isinstance(obj, (np.floating,)):
        return float(obj)
    if isinstance(obj, (np.ndarray,)):
        return obj.tolist()
    # ã“ã“ã«æ¥ã‚‹ã®ã¯ str ã‚„ bool ãªã© json ãŒæ‰±ãˆã‚‹å‹
    return obj

def calculate_metrics(df):
    """è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—"""
    if df.empty:
        return df

    # æœ€é©è§£æ¨å®šå¼ 3nÂ²/8 ã¨ã®å·®åˆ†
    df['estimated_optimal'] = (3 * df['size'] * df['size']) / 8
    df['diff_from_estimated'] = df['num_moves'] - df['estimated_optimal']

    # nÂ²ã¨ã®å·®åˆ†
    df['n_squared'] = df['size'] * df['size']
    df['diff_from_n_squared'] = df['num_moves'] - df['n_squared']

    # æ¢ç´¢åŠ¹ç‡ (solved problems per second based on nodes explored)
    df['search_efficiency'] = df['nodes_explored'] / (df['calculation_time_ms'] / 1000)

    # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆå‚è€ƒå€¤ï¼‰- å°ã•ã„ã»ã©è‰¯ã„
    if len(df) > 1:  # æ­£è¦åŒ–ã®ãŸã‚ã«è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
        time_normalized = (df['calculation_time_ms'] - df['calculation_time_ms'].min()) / (
                df['calculation_time_ms'].max() - df['calculation_time_ms'].min() + 1e-10)
        moves_normalized = (df['num_moves'] - df['num_moves'].min()) / (
                df['num_moves'].max() - df['num_moves'].min() + 1e-10)
        efficiency_normalized = 1 - ((df['search_efficiency'] - df['search_efficiency'].min()) / (
            df['search_efficiency'].max() - df['search_efficiency'].min() + 1e-10))

        df['composite_score'] = time_normalized + moves_normalized + efficiency_normalized
    else:
        df['composite_score'] = 1.0

    return df


def calculate_summary(df):
    """ã‚µãƒãƒªãƒ¼çµ±è¨ˆã‚’è¨ˆç®—"""
    if df.empty or 'solved' not in df.columns:
        return None

    solved_df = df[df['solved'] == True]

    summary = {
            'total_problems': len(df),
            'solved_problems': len(solved_df),
            'total_calculation_time_ms': df['calculation_time_ms'].sum(),
            'avg_calculation_time_ms': df['calculation_time_ms'].mean(),
            'total_actual_time_ms': df['actual_execution_time_ms'].sum(),
            'avg_actual_time_ms': df['actual_execution_time_ms'].mean(),
            'total_nodes_explored': df['nodes_explored'].sum(),
            'avg_nodes_explored': df['nodes_explored'].mean(),
            'avg_moves': df['num_moves'].mean(),
            'avg_diff_from_estimated': df['diff_from_estimated'].mean(),
            'avg_diff_from_n_squared': df['diff_from_n_squared'].mean(),
            'avg_search_efficiency': df['search_efficiency'].mean(),
            'avg_composite_score': df['composite_score'].mean()
            }
    return summary


@st.cache_data
def load_benchmark_results():
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’èª­ã¿è¾¼ã‚€"""
    results_file = "benchmark_results.csv"
    summary_file = "benchmark_summary.json"

    if not os.path.exists(results_file):
        return pd.DataFrame(), None

    df = pd.read_csv(results_file)

    summary = None
    if os.path.exists(summary_file):
        try:
            with open(summary_file, 'r', encoding='utf-8') as f:
                # First, check if the file is not empty to avoid an error
                if os.path.getsize(summary_file) > 0:
                    summary = json.load(f)
                else:
                    st.warning(f"è­¦å‘Š: '{summary_file}' ã¯ç©ºã§ã™ã€‚ç„¡è¦–ã•ã‚Œã¾ã™ã€‚")
        except json.JSONDecodeError as e:
            st.warning(f"'{summary_file}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            st.info("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å†å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«ä¿®å¾©ï¼ˆä¸Šæ›¸ãï¼‰ã•ã‚Œã¾ã™ã€‚")
            # On error, ensure summary remains None so the app can proceed
            summary = None

    return df, summary


def kill_process_tree(process):
    """ãƒ—ãƒ­ã‚»ã‚¹ãƒ„ãƒªãƒ¼å…¨ä½“ã‚’ç¢ºå®Ÿã«çµ‚äº†ã™ã‚‹"""
    try:
        # psutilã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ã‚»ã‚¹ãƒ„ãƒªãƒ¼ã‚’å–å¾—
        parent = psutil.Process(process.pid)
        children = parent.children(recursive=True)

        # å­ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰é †ã«çµ‚äº†
        for child in children:
            try:
                child.terminate()
            except psutil.NoSuchProcess:
                pass

        # è¦ªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†
        try:
            parent.terminate()
        except psutil.NoSuchProcess:
            pass

        # å°‘ã—å¾…ã£ã¦ã‹ã‚‰å¼·åˆ¶çµ‚äº†
        gone, still_alive = psutil.wait_procs(children + [parent], timeout=3)
        for p in still_alive:
            try:
                p.kill()
            except psutil.NoSuchProcess:
                pass

    except (psutil.NoSuchProcess, psutil.AccessDenied, OSError):
        # ãƒ—ãƒ­ã‚»ã‚¹ãŒæ—¢ã«çµ‚äº†ã—ã¦ã„ã‚‹å ´åˆã‚„ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒãªã„å ´åˆ
        # é€šå¸¸ã®ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ã‚’è©¦è¡Œ
        try:
            process.terminate()
            process.wait(timeout=3)
        except subprocess.TimeoutExpired:
            process.kill()
            process.wait()
        except OSError:
            pass


def run_single_problem(executable_path, problem_path):
    """å˜ä¸€ã®å•é¡Œã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™"""
    cat_process = None
    astar_process = None

    try:
        start_time = time.perf_counter()

        # cat problem_file | ./astar_manhattan ã®å½¢ã§å®Ÿè¡Œ
        cat_process = subprocess.Popen(
                ["cat", problem_path],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
                )

        astar_process = subprocess.Popen(
                [executable_path],
                stdin=cat_process.stdout,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
                )

        cat_process.stdout.close()

        stdout, stderr = astar_process.communicate(timeout=60)
        end_time = time.perf_counter()

        execution_time = (end_time - start_time) * 1000  # ãƒŸãƒªç§’

        if astar_process.returncode != 0:
            return None, f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {stderr}"

        try:
            output_data = json.loads(stdout.strip())
            output_data['actual_execution_time_ms'] = execution_time
            output_data['problem_path'] = problem_path
            return output_data, None
        except json.JSONDecodeError as e:
            return None, f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}\nå‡ºåŠ›: {stdout}"

    except subprocess.TimeoutExpired:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã®å‡¦ç†ã‚’æ”¹å–„
        error_msg = "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (60ç§’)"

        # ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºå®Ÿã«çµ‚äº†
        if astar_process is not None:
            kill_process_tree(astar_process)
        if cat_process is not None:
            kill_process_tree(cat_process)

        return None, error_msg

    except Exception as e:
        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if astar_process is not None:
            try:
                kill_process_tree(astar_process)
            except:
                pass
        if cat_process is not None:
            try:
                kill_process_tree(cat_process)
            except:
                pass

        return None, f"äºˆæœŸã›ã¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"


def run_benchmark_with_config(executable_path, problems_dir, problems_per_size, min_size, max_size):
    """è¨­å®šã‚’ä½¿ç”¨ã—ã¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œï¼ˆã‚µã‚¤ã‚ºç¯„å›²æŒ‡å®šä»˜ãï¼‰"""
    if not os.path.exists(executable_path):
        st.error(f"å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ« '{executable_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    if not os.path.exists(problems_dir):
        st.error(f"å•é¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{problems_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # å•é¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    problem_files = []
    # problemsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚©ãƒ«ãƒ€('4x4', '5x5'ãªã©)ã‚’ã‚½ãƒ¼ãƒˆã—ã¦å–å¾—
    size_dirs = sorted([d for d in Path(problems_dir).iterdir() if d.is_dir()], key=lambda d: int(d.name.split('x')[0]))

    for size_dir in size_dirs:
        try:
            # ## è¿½åŠ : ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰ã‚µã‚¤ã‚ºã‚’ãƒ‘ãƒ¼ã‚¹ ##
            current_size = int(size_dir.name.split('x')[0])
            # ## è¿½åŠ : æŒ‡å®šã•ã‚ŒãŸã‚µã‚¤ã‚ºç¯„å›²å¤–ã§ã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ— ##
            if not (min_size <= current_size <= max_size):
                continue
        except (ValueError, IndexError):
            # '4x4' ã®ã‚ˆã†ãªå½¢å¼ã§ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ç„¡è¦–
            continue

        # å„ã‚µã‚¤ã‚ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å•é¡Œãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.jsonï¼‰ã‚’åå‰é †ã§ã‚½ãƒ¼ãƒˆã—ã¦å–å¾—
        files_in_dir = sorted(size_dir.glob("*.json"), key=lambda path: int(path.stem.lstrip('p')))
        # æŒ‡å®šã•ã‚ŒãŸå•é¡Œæ•°ã ã‘ã‚¹ãƒ©ã‚¤ã‚¹ã—ã¦ã€å…¨ä½“ã®ãƒªã‚¹ãƒˆã«è¿½åŠ 
        problem_files.extend(files_in_dir[:problems_per_size])

    if not problem_files:
        st.error(f"æŒ‡å®šã•ã‚ŒãŸç¯„å›² ({min_size}x{min_size}ã€œ{max_size}x{max_size}) ã§å•é¡Œãƒ•ã‚¡ã‚¤ãƒ«(.json)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    st.info(f"å®Ÿè¡Œã™ã‚‹å•é¡Œæ•°: {len(problem_files)}")

    progress_bar = st.progress(0, text="ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œæº–å‚™ä¸­...")
    results = []
    start_time = time.time()

    for i, problem_path in enumerate(problem_files):
        progress = (i + 1) / len(problem_files)
        progress_bar.progress(progress, text=f"å®Ÿè¡Œä¸­ ({i + 1}/{len(problem_files)}): {problem_path.name}")

        result, error = run_single_problem(executable_path, str(problem_path))

        if result:
            try:
                path_parts = problem_path.parts
                size_str = path_parts[-2]
                problem_id_str = problem_path.stem
                size = int(size_str.split('x')[0])

                result['problem_id'] = problem_id_str
                result['size'] = size
                results.append(result)
            except (IndexError, ValueError) as e:
                st.warning(f"ãƒ‘ã‚¹ '{problem_path}' ã‹ã‚‰ã‚µã‚¤ã‚ºã¾ãŸã¯IDã®è§£æã«å¤±æ•—: {e}")
        else:
            st.warning(f"å•é¡Œ {problem_path.name} ã§ã‚¨ãƒ©ãƒ¼: {error}")

    end_time = time.time()

    if results:
        df = pd.DataFrame(results)
        df = calculate_metrics(df)
        df.to_csv("benchmark_results.csv", index=False)

        summary = calculate_summary(df)
        if summary:
            with open("benchmark_summary.json", 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False, default=to_serializable)

        progress_bar.progress(1.0, text="å®Œäº†ï¼")
        st.success(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œå®Œäº†ï¼ (åˆè¨ˆæ™‚é–“: {end_time - start_time:.2f}ç§’)")
        st.success(f"æˆåŠŸ: {len(results)}/{len(problem_files)} å•é¡Œ")

        load_benchmark_results.clear()
        st.rerun()
    else:
        st.error("å®Ÿè¡Œã«æˆåŠŸã—ãŸå•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


def display_metrics_overview(summary):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ¦‚è¦ã‚’è¡¨ç¤º"""
    st.header("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¦‚è¦")

    col1, col2, col3, col4 = st.columns(4)
    solved_percentage = (summary['solved_problems'] / summary['total_problems'] * 100) if summary['total_problems'] > 0 else 0

    with col1:
        st.markdown(f"""
        <div class="metric-card success-metric">
            <h3>è§£æ±ºç‡</h3>
            <h2>{summary.get('solved_problems', 0)}/{summary.get('total_problems', 0)}</h2>
            <p>{solved_percentage:.1f}%</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="metric-card info-metric">
            <h3>å¹³å‡è¨ˆç®—æ™‚é–“</h3>
            <h2>{summary.get('avg_calculation_time_ms', 0):.2f}ms</h2>
            <p>ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å†…éƒ¨</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown(f"""
        <div class="metric-card warning-metric">
            <h3>å¹³å‡æ¢ç´¢ãƒãƒ¼ãƒ‰</h3>
            <h2>{summary.get('avg_nodes_explored', 0):,.0f}</h2>
            <p>nodes</p>
        </div>
        """, unsafe_allow_html=True)

    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <h3>å¹³å‡æ‰‹æ•°</h3>
            <h2>{summary.get('avg_moves', 0):.1f}</h2>
            <p>moves</p>
        </div>
        """, unsafe_allow_html=True)


def plot_time_performance(df):
    """æ™‚é–“æ€§èƒ½ã®å¯è¦–åŒ–"""
    st.subheader("â±ï¸ æ™‚é–“æ€§èƒ½åˆ†æ")

    col1, col2 = st.columns(2)

    with col1:
        size_time = df.groupby('size')['calculation_time_ms'].agg(['mean', 'std']).reset_index()
        fig = px.line(size_time, x='size', y='mean',
                      title='ã‚µã‚¤ã‚ºåˆ¥å¹³å‡è¨ˆç®—æ™‚é–“',
                      labels={'mean': 'å¹³å‡è¨ˆç®—æ™‚é–“ (ms)', 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        fig = px.histogram(df, x='calculation_time_ms',
                           title='è¨ˆç®—æ™‚é–“åˆ†å¸ƒ',
                           labels={'calculation_time_ms': 'è¨ˆç®—æ™‚é–“ (ms)', 'count': 'å•é¡Œæ•°'},
                           nbins=50)
        st.plotly_chart(fig, use_container_width=True)


def plot_search_performance(df):
    """æ¢ç´¢æ€§èƒ½ã®å¯è¦–åŒ–"""
    st.subheader("ğŸ” æ¢ç´¢æ€§èƒ½åˆ†æ")

    col1, col2 = st.columns(2)

    with col1:
        fig = px.box(df, x='size', y='nodes_explored',
                     title='ã‚µã‚¤ã‚ºåˆ¥æ¢ç´¢ãƒãƒ¼ãƒ‰æ•°åˆ†å¸ƒ',
                     labels={'nodes_explored': 'æ¢ç´¢ãƒãƒ¼ãƒ‰æ•°', 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º'})
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        fig = px.scatter(df, x='size', y='search_efficiency',
                         color='calculation_time_ms',
                         title='æ¢ç´¢åŠ¹ç‡ vs ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º',
                         labels={'search_efficiency': 'æ¢ç´¢åŠ¹ç‡ (nodes/sec)',
                                 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º',
                                 'calculation_time_ms': 'è¨ˆç®—æ™‚é–“ (ms)'},
                         color_continuous_scale='viridis')
        st.plotly_chart(fig, use_container_width=True)


def plot_solution_quality(df):
    """è§£ã®å“è³ªåˆ†æ"""
    st.subheader("ğŸ¯ è§£ã®å“è³ªåˆ†æ")
    if 'diff_from_estimated' not in df.columns:
        st.info("è§£ã®å“è³ªã‚’åˆ†æã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        fig = px.scatter(df, x='size', y='diff_from_estimated',
                         color='num_moves',
                         title='æ¨å®šæœ€é©è§£(3nÂ²/8)ã‹ã‚‰ã®å·®åˆ†',
                         labels={'diff_from_estimated': 'å·®åˆ† (moves)',
                                 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º',
                                 'num_moves': 'å®Ÿéš›ã®æ‰‹æ•°'},
                         color_continuous_scale='RdYlBu_r')
        fig.add_hline(y=0, line_dash="dash", line_color="red", annotation_text="ç†è«–æœ€é©å€¤")
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        fig = px.scatter(df, x='size', y='diff_from_n_squared',
                         color='composite_score',
                         title='ç†è«–æœ€å¤§å€¤(nÂ²)ã‹ã‚‰ã®å·®åˆ†',
                         labels={'diff_from_n_squared': 'å·®åˆ† (moves)',
                                 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º',
                                 'composite_score': 'ç·åˆã‚¹ã‚³ã‚¢'},
                         color_continuous_scale='viridis')
        st.plotly_chart(fig, use_container_width=True)


def plot_manhattan_comparison(df):
    """ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢ã¨ã®æ¯”è¼ƒ"""
    if all(col in df.columns for col in ['diff_from_manhattan_min', 'diff_from_manhattan_max']):
        st.subheader("ğŸ“ ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢ãƒ™ãƒ¼ã‚¹æ¯”è¼ƒ")
        col1, col2 = st.columns(2)
        with col1:
            fig = px.box(df, x='size', y='diff_from_manhattan_min',
                         title='ãƒãƒ³ãƒãƒƒã‚¿ãƒ³æœ€å°å€¤ã‹ã‚‰ã®å·®åˆ†åˆ†å¸ƒ',
                         labels={'diff_from_manhattan_min': 'å·®åˆ† (moves)', 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º'})
            st.plotly_chart(fig, use_container_width=True)
        with col2:
            fig = px.box(df, x='size', y='diff_from_manhattan_max',
                         title='ãƒãƒ³ãƒãƒƒã‚¿ãƒ³æœ€å¤§å€¤ã‹ã‚‰ã®å·®åˆ†åˆ†å¸ƒ',
                         labels={'diff_from_manhattan_max': 'å·®åˆ† (moves)', 'size': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º'})
            st.plotly_chart(fig, use_container_width=True)


def plot_comprehensive_analysis(df):
    """ç·åˆåˆ†æ (å„æŒ‡æ¨™ã‚’0-100ã®ã‚¹ã‚³ã‚¢ã«æ­£è¦åŒ–)"""
    st.subheader("ğŸ“ˆ ç·åˆåˆ†æ")
    st.info("å„æŒ‡æ¨™ã‚’0-100ã®ã‚¹ã‚³ã‚¢ã«å¤‰æ›ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚å€¤ãŒ100ã«è¿‘ã„ã»ã©ã€ãã®ã‚µã‚¤ã‚ºã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚")

    # NaNã‚’å«ã‚€è¡Œã¯é›†è¨ˆã‹ã‚‰é™¤å¤–
    agg_df = df.dropna(subset=['calculation_time_ms', 'nodes_explored', 'num_moves'])

    if agg_df.empty:
        st.warning("ç·åˆåˆ†æã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    size_summary = agg_df.groupby('size').agg({
        'calculation_time_ms': 'mean',
        'nodes_explored': 'mean',
        'num_moves': 'mean',
        'search_efficiency': 'mean',
        'composite_score': 'mean'
        }).reset_index()

    # æ­£è¦åŒ–å¯¾è±¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    metrics_to_scale = {
            'calculation_time_ms': 'lower_is_better',
            'nodes_explored': 'lower_is_better',
            'num_moves': 'lower_is_better',
            'composite_score': 'lower_is_better',
            'search_efficiency': 'higher_is_better'
            }

    scaled_summary = size_summary.copy()

    for metric, scale_type in metrics_to_scale.items():
        if metric in scaled_summary.columns:
            min_val = scaled_summary[metric].min()
            max_val = scaled_summary[metric].max()

            # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
            if (max_val - min_val) == 0:
                scaled_summary[metric] = 100.0
                continue

            # Min-Max ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            if scale_type == 'lower_is_better':
                # å€¤ãŒå°ã•ã„ã»ã©100ã«è¿‘ã¥ã
                scaled_summary[metric] = 100 * (1 - (scaled_summary[metric] - min_val) / (max_val - min_val))
            else: # higher_is_better
                # å€¤ãŒå¤§ãã„ã»ã©100ã«è¿‘ã¥ã
                scaled_summary[metric] = 100 * ((scaled_summary[metric] - min_val) / (max_val - min_val))

    # è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é †ç•ªã¨åå‰ã‚’å®šç¾©
    display_metrics = {
            'calculation_time_ms': 'æ™‚é–“åŠ¹ç‡ã‚¹ã‚³ã‚¢',
            'nodes_explored': 'æ¢ç´¢ç©ºé–“ã‚¹ã‚³ã‚¢',
            'num_moves': 'è§£å“è³ªã‚¹ã‚³ã‚¢',
            'search_efficiency': 'æ¢ç´¢åŠ¹ç‡ã‚¹ã‚³ã‚¢',
            'composite_score': 'ç·åˆã‚¹ã‚³ã‚¢'
            }

    available_metrics = [m for m in display_metrics.keys() if m in scaled_summary.columns]

    if available_metrics:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚µã‚¤ã‚ºã«è¨­å®šã—ã€è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ
        heatmap_data = scaled_summary.set_index('size')[available_metrics].T
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆYè»¸ã®ãƒ©ãƒ™ãƒ«ï¼‰ã‚’æ—¥æœ¬èªã«ç½®æ›
        heatmap_data = heatmap_data.rename(index=display_metrics)

        fig = px.imshow(heatmap_data,
                        title='ã‚µã‚¤ã‚ºåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—',
                        labels={'x': 'ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚º', 'y': 'è©•ä¾¡æŒ‡æ¨™', 'color': 'ã‚¹ã‚³ã‚¢ (0-100)'},
                        color_continuous_scale='RdYlGn', # èµ¤(æ‚ªã„) -> é»„ -> ç·‘(è‰¯ã„) ã®ã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
                        aspect="auto"
                        )
        st.plotly_chart(fig, use_container_width=True)
def display_detailed_table(df):
    """è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"""
    st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿")

    col1, col2, col3 = st.columns(3)
    with col1:
        size_filter = st.multiselect("ãƒ‘ã‚ºãƒ«ã‚µã‚¤ã‚ºé¸æŠ",
                                     options=sorted(df['size'].dropna().unique().astype(int)),
                                     default=sorted(df['size'].dropna().unique().astype(int)))
    with col2:
        # NaNã‚’ç„¡è¦–ã—ã¦æœ€å°ãƒ»æœ€å¤§ã‚’è¨ˆç®—
        min_time, max_time = float(df['calculation_time_ms'].min()), float(df['calculation_time_ms'].max())
        time_range = st.slider("è¨ˆç®—æ™‚é–“ç¯„å›² (ms)", min_value=min_time, max_value=max_time, value=(min_time, max_time))

    with col3:
        # ## å¤‰æ›´: ãƒ•ã‚£ãƒ«ã‚¿ã®é¸æŠè‚¢ã‚’å¢—ã‚„ã™ ##
        solved_filter = st.selectbox("è¡¨ç¤ºå¯¾è±¡", options=["ã™ã¹ã¦", "è§£æ±ºæ¸ˆã¿ã®ã¿", "å¤±æ•—ã®ã¿"], index=0)

    filtered_df = df[df['size'].isin(size_filter)]

    # æ™‚é–“ã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯è§£æ±ºæ¸ˆã¿ã®ã‚‚ã®ã«ã®ã¿é©ç”¨
    solved_part = filtered_df[filtered_df['solved'] == True]
    failed_part = filtered_df[filtered_df['solved'] == False]

    solved_part = solved_part[
            (solved_part['calculation_time_ms'] >= time_range[0]) &
            (solved_part['calculation_time_ms'] <= time_range[1])
            ]

    filtered_df = pd.concat([solved_part, failed_part])

    if solved_filter == "è§£æ±ºæ¸ˆã¿ã®ã¿":
        filtered_df = filtered_df[filtered_df['solved'] == True]
    elif solved_filter == "å¤±æ•—ã®ã¿":
        filtered_df = filtered_df[filtered_df['solved'] == False]


    # ## å¤‰æ›´: erroråˆ—ã‚’è¿½åŠ  ##
    display_columns = [
            'size', 'problem_id', 'solved', 'num_moves', 'calculation_time_ms',
            'nodes_explored', 'search_efficiency',
            'diff_from_estimated', 'composite_score', 'error'
            ]
    available_columns = [col for col in display_columns if col in filtered_df.columns]

    # NaNã‚’ 'N/A' ã«ç½®æ›ã—ã¦è¡¨ç¤º
    st.dataframe(filtered_df[available_columns].fillna('N/A').round(4), use_container_width=True, height=400)
    st.write(f"è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿æ•°: {len(filtered_df)} / {len(df)}")

def main():
    st.title("ğŸ” é«˜å°‚ãƒ—ãƒ­ã‚³ãƒ³ç«¶æŠ€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    st.sidebar.title("âš™ï¸ æ“ä½œãƒ‘ãƒãƒ«")
    executable_path = st.sidebar.text_input("å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", value="./astar_manhattan")
    problems_dir = st.sidebar.text_input("å•é¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value="problems")

    # ## è¿½åŠ : å•é¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªã‚µã‚¤ã‚ºã®ç¯„å›²ã‚’è‡ªå‹•æ¤œå‡º ##
    min_avail = 4
    max_avail = 24 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    problem_path_obj = Path(problems_dir)
    if problem_path_obj.exists() and problem_path_obj.is_dir():
        available_sizes = []
        for d in problem_path_obj.iterdir():
            if d.is_dir():
                try:
                    size = int(d.name.split('x')[0])
                    available_sizes.append(size)
                except (ValueError, IndexError):
                    pass # '4x4'ã®ã‚ˆã†ãªåå‰ã§ãªã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ç„¡è¦–
        if available_sizes:
            min_avail = min(available_sizes)
            max_avail = max(available_sizes)

    # ## è¿½åŠ : ã‚µã‚¤ã‚ºç¯„å›²ã‚’æŒ‡å®šã™ã‚‹ãŸã‚ã®å…¥åŠ›æ¬„ ##
    st.sidebar.markdown("---")
    st.sidebar.markdown("##### å®Ÿè¡Œç¯„å›²ã®è¨­å®š")
    col1, col2 = st.sidebar.columns(2)
    with col1:
        min_size = st.number_input("æœ€å°ã‚µã‚¤ã‚º", min_value=min_avail, max_value=max_avail, value=min_avail, step=2)
    with col2:
        max_size = st.number_input("æœ€å¤§ã‚µã‚¤ã‚º", min_value=min_avail, max_value=max_avail, value=max_avail, step=2)

    if min_size > max_size:
        st.sidebar.error("æœ€å°ã‚µã‚¤ã‚ºãŒæœ€å¤§ã‚µã‚¤ã‚ºã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚")

    problems_per_size = st.sidebar.number_input(
            "å„ã‚µã‚¤ã‚ºã§å®Ÿè¡Œã™ã‚‹å•é¡Œæ•°",
            min_value=1,
            value=5,
            step=1,
            help="å„ã‚µã‚¤ã‚ºï¼ˆ4x4, 5x5...ï¼‰ã”ã¨ã«ã€ã“ã“ã§æŒ‡å®šã—ãŸæ•°ã®å•é¡Œã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åé †ã«å–å¾—ã—ã¾ã™ã€‚"
            )
    st.sidebar.markdown("---")

    # ## å¤‰æ›´: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œãƒœã‚¿ãƒ³ã®ãƒ­ã‚¸ãƒƒã‚¯ ##
    if st.sidebar.button("ğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ", type="primary", disabled=(min_size > max_size)):
        # ## å¤‰æ›´: min_sizeã¨max_sizeã‚’å¼•æ•°ã«è¿½åŠ  ##
        run_benchmark_with_config(executable_path, problems_dir, problems_per_size, min_size, max_size)

    df, summary = load_benchmark_results()

    if df.empty:
        st.warning("âš ï¸ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€ã¾ãšãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    st.sidebar.success(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
    st.sidebar.info(f"å•é¡Œæ•°: {len(df)}")
    st.sidebar.info(f"ã‚µã‚¤ã‚ºç¯„å›²: {df['size'].min()}x{df['size'].min()} - {df['size'].max()}x{df['size'].max()}")

    if summary:
        display_metrics_overview(summary)

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "â±ï¸ æ™‚é–“æ€§èƒ½", "ğŸ” æ¢ç´¢æ€§èƒ½", "ğŸ¯ è§£å“è³ª", "ğŸ“ˆ ç·åˆåˆ†æ", "ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿"
        ])

    with tab1:
        plot_time_performance(df)
    with tab2:
        plot_search_performance(df)
    with tab3:
        plot_solution_quality(df)
        plot_manhattan_comparison(df)
    with tab4:
        plot_comprehensive_analysis(df)
    with tab5:
        display_detailed_table(df)

    st.markdown("---")
    st.markdown("ğŸš€ A*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ  | Built with Streamlit")

if __name__ == "__main__":
    main()
